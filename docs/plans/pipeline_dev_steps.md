현재 구조는 앞서 설명한 그대로 동작 중이에요. `QueryExecutionService`가 DuckDB `query_history` + `query_result_<run_id>` 테이블을 생성하고, 검증 노드가 그 정보를 `state.verification_result`에 담아서 반환합니다. 단건 결과를 빠르게 확인하고 버리는 워크플로우에 초점이 맞춰져 있어서, 세션별 임시 테이블이 계속 늘어나는 형태죠. 지금도 필요하면 해당 테이블을 그대로 `SELECT * FROM query_result_<run_id>`로 읽어오는 건 가능하지만, 이름 규칙이 run 단위라 장기 유지나 재사용에는 불편합니다.

제안해주신 “무조건 mart 테이블에 적재하고, 차트는 거기서 `SELECT *`만 한다” 전략은 통일성·운영 편의 면에서 확실한 장점이 있습니다. 대신 고려할 부분 몇 가지를 정리해볼게요:

- **dbt 파이프라인 연동 비용**  
  - 모든 분석 결과를 mart로 승격하려면, 에이전트가 생성한 SQL을 그대로 저장하는게 아니라 dbt 모델(혹은 seed)에 편입시켜야 합니다.  
  - 자동화하려면 `agent_result_<flow_id>` 같은 모델 템플릿을 만들고, SQL을 해당 모델의 소스 파일로 밀어 넣은 다음 dbt run을 트리거하는 식이 될 겁니다.  
  - dbt run 시간이 짧으면 상관없지만, 모델 수가 늘면 에이전트 응답 속도가 느려질 수 있습니다.

- **flow 개념 도입**  
  - 제안하신 대로 “분석 → mart 생성 → 차트는 mart 로드”라는 고정 플로우를 정립하면, UI/백엔드가 처리해야 할 예외 케이스가 크게 줄어듭니다.  
  - 이후 refresh는 동일 flow를 재실행하면 되고, 스케줄링이나 lineage 관리도 dbt에서 가져갈 수 있습니다.  
  - 다만 현재 에이전트는 on-demand ad-hoc 질문도 다룰 텐데, 이런 즉석 질문까지 mart를 강제할지, 아니면 “flow로 승격” 버튼을 둬서 사용자가 선택하게 할지 정책을 정해야 합니다.

- **데이터 볼륨 및 보존 정책**  
  - mart를 장기 보관한다면 주기적인 정리/갱신, 스키마 관리가 필요합니다. 반대로 임시 결과(가벼운 탐색성 질의)는 빠르게 버려도 괜찮으면 지금 구조가 더 단순합니다.  
  - 용량 측면에서도 모든 결과를 mart로 유지하면 저장 공간이 계속 늘어날 수 있으므로, TTL이나 버저닝 전략을 명확히 해야 합니다.

- **현재 코드 영향**  
  - 검증 노드를 mart 파이프라인으로 바꾸면 `QueryExecutionService`가 하는 역할(당장 DuckDB 결과 테이블 생성) 대신, dbt 실행 요청 + 상태 추적 로직이 필요합니다.  
  - `state.verification_result` 구조도 “결과 테이블 이름” 대신 “등록된 mart 이름/flow id/dbt 상태” 등으로 바뀌어야 할 겁니다.  
  - 프론트도 즉시 미리보기 대신 “mart 생성 중 → 완료되면 차트에서 조회” 같은 UX를 적용해야 합니다.

제 생각에는:

1. **단기**: 현재처럼 `query_result_<run_id>` 테이블과 `query_history`를 유지하되, TTL/정리 배치 작업 추가해 관리 문제를 줄입니다. 빠른 피드백이 필요할 때 유리합니다.
2. **중기**: “이 결과를 flow로 승격” 기능을 도입해, 사용자가 의도할 때만 mart + dbt 파이프라인을 돌립니다. 이때 flow 실행과 결과 테이블 이름 규칙을 표준화합니다.
3. **장기**: 전사적으로 mart 기반 대시보드/차트를 쓰기로 확정하고, ad-hoc 분석까지 모두 flow 구조로 통일하는 시점에는 에이전트의 verifier를 dbt 트리거로 전환합니다.

이렇게 단계별로 도입하면 현재 기능을 유지하면서도, 장기적으로 제안하신 통일 구조로 자연스럽게 넘어갈 수 있을 것 같아요. 필요하면 다음 단계로 구체적인 설계/작업 순서 정리해드릴게요!